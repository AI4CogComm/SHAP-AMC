{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af924a7-e622-45e2-9d7d-505ba5b00e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WANGJINGCHUN\\AppData\\Local\\Temp\\ipykernel_145692\\3471678095.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import rml128_dtiny\n",
    "import os\n",
    "from imp import reload\n",
    "from keras.layers import Input,Dense,Conv1D,MaxPool1D,ReLU,BatchNormalization,Dropout,Softmax,Attention\n",
    "from keras.layers import LSTM,CuDNNLSTM,Bidirectional,Flatten,Reshape,Concatenate,Layer,GlobalMaxPooling1D\n",
    "from keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0df03b4-573a-484b-a9f6-5689eb941c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bdb742d-cb37-4be8-895a-fe55a19a0912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(6600, 128, 2)\n",
      "(2200, 128, 2)\n",
      "(660, 128, 2)\n",
      "(6600, 11)\n",
      "(2200, 11)\n",
      "(660, 11)\n"
     ]
    }
   ],
   "source": [
    "reload(rml128_dtiny)\n",
    "(mods,snrs,lbl),(X_train1,Y_train1),(X_val1,Y_val1),(X_test1,Y_test1),(train_idx1,val_idx1,test_idx1) = \\\n",
    "    rml128_dtiny.load_data()\n",
    "classes = mods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23e74d8-f6e5-4414-b629-0eabbf07e43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(6600, 128, 2)\n",
      "(2200, 128, 2)\n",
      "(1320, 128, 2)\n",
      "(6600, 11)\n",
      "(2200, 11)\n",
      "(1320, 11)\n"
     ]
    }
   ],
   "source": [
    "reload(rml128_dtiny)\n",
    "(mods,snrs,lbl),(X_train2,Y_train2),(X_val2,Y_val2),(X_test2,Y_test2),(train_idx2,val_idx2,test_idx2) = \\\n",
    "    rml128_dtiny.load_data()\n",
    "classes = mods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6127e99e-db08-4c64-947e-29829575d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(6600, 128, 2)\n",
      "(2200, 128, 2)\n",
      "(1320, 128, 2)\n",
      "(6600, 11)\n",
      "(2200, 11)\n",
      "(1320, 11)\n"
     ]
    }
   ],
   "source": [
    "reload(rml128_dtiny)\n",
    "(mods,snrs,lbl),(X_train3,Y_train3),(X_val3,Y_val3),(X_test3,Y_test3),(train_idx3,val_idx3,test_idx3) = \\\n",
    "    rml128_dtiny.load_data()\n",
    "classes = mods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ccdb66-4353-45cc-b672-20d9928d1267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(6600, 128, 2)\n",
      "(2200, 128, 2)\n",
      "(1320, 128, 2)\n",
      "(6600, 11)\n",
      "(2200, 11)\n",
      "(1320, 11)\n"
     ]
    }
   ],
   "source": [
    "reload(rml128_dtiny)\n",
    "(mods,snrs,lbl),(X_train4,Y_train4),(X_val4,Y_val4),(X_test4,Y_test4),(train_idx4,val_idx4,test_idx4) = \\\n",
    "    rml128_dtiny.load_data()\n",
    "classes = mods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ffbc5c-2879-440c-b6f7-3077f926f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(11)\n",
    "model.compile(optimizer=Adam(learning_rate = 0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model = tf.keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ac95b53-6d61-4c23-8445-58bea5a11a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 4ms/step - loss: 0.2831 - accuracy: 0.9144\n",
      "第一个测试集的准确率为: 91.44%\n",
      "第一个测试集的损失为: 28.31%\n"
     ]
    }
   ],
   "source": [
    "loss1, accuracy1 = model.evaluate(x=X_test1, y=Y_test1)\n",
    "print(\"第一个测试集的准确率为: {:.2f}%\".format(accuracy1 * 100))\n",
    "print(\"第一个测试集的损失为: {:.2f}%\".format(loss1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53964b7-e0f5-4f4a-b37d-ca056a65358f",
   "metadata": {},
   "source": [
    "## 攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "145e10c4-8d32-4dd0-8acf-fd6674b70ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\envs\\wtfgpu\\lib\\site-packages\\art\\estimators\\certification\\__init__.py:29: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import cleverhans\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.tf2.attacks.basic_iterative_method import basic_iterative_method\n",
    "import carlini_wagner_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb7b2de5-bc89-430a-ba08-ca7930a47342",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "def create_adversarial_pattern(input_signal, input_label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_signal)\n",
    "        prediction = model(input_signal)\n",
    "        loss = loss_object(input_label, prediction)\n",
    "    gradient = tape.gradient(loss, input_signal)\n",
    "    # 对梯度使用sign函数，创建扰动\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b0c1bd-c2ee-4d21-aa8a-40eda59efd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbation_gen(X,Y,eps):\n",
    "    perturbations = [] #用于存储生成的干扰，最终和信号的形状一样\n",
    "    for i in range(len(X)):\n",
    "        x_i =  tf.convert_to_tensor(np.reshape(X[i].copy(),(1,128,2)))\n",
    "        y_i =  tf.convert_to_tensor(np.reshape(Y[i].copy(),(1,11)))\n",
    "        perturbations.append(create_adversarial_pattern(x_i, y_i))#*0.5+0.5可以转换到0-1\n",
    "    perturbations = np.squeeze(np.array(perturbations))#生成最终的干扰信号(6600,128,2)\n",
    "    for i in range(len(X)):\n",
    "        range_am_i = np.max(X[i,:,0])-np.min(X[i,:,0])\n",
    "        range_ph_i = np.max(X[i,:,1])-np.min(X[i,:,1])\n",
    "        perturbations[i,:,0] = range_am_i * perturbations[i,:,0]\n",
    "        perturbations[i,:,1] = range_ph_i * perturbations[i,:,1] \n",
    "    return X.copy() + np.squeeze(eps*perturbations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37df3f56-977a-4f38-a166-2f67077e816d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pgd\n",
    "eps = 0.025\n",
    "num_iter = 10\n",
    "eps_iterr = 0.001\n",
    "rand_init = 0.3*eps\n",
    "xtrain_adv1 = projected_gradient_descent(model, X_train1.copy(), eps, eps_iterr,num_iter, np.inf,\n",
    "                                         clip_min=-1,clip_max=1,rand_init=rand_init, rand_minmax=0.3)\n",
    "loss, accuracy = model.evaluate(x=xtrain_adv1, y=Y_train1)\n",
    "print(\"第1个训练集的准确率为: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"第1个训练集的损失为: {:.2f}%\".format(loss * 100))\n",
    "xval_adv1 = projected_gradient_descent(model, X_val1.copy(), eps, eps_iterr,num_iter, np.inf,\n",
    "                                       clip_min=-1,clip_max=1,rand_init=rand_init, rand_minmax=0.3)\n",
    "loss, accuracy = model.evaluate(x=xval_adv1, y=Y_val1)\n",
    "print(\"第1个验证集的准确率为: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"第1个验证集的损失为: {:.2f}%\".format(loss * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00c3626-f390-412a-9881-c8a73facaed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_adv2 = perturbation_gen(X_train2.copy(),Y_train2.copy(),eps)\n",
    "loss, accuracy = model.evaluate(x=xtrain_adv2, y=Y_train2)\n",
    "print(\"第2个训练集的准确率为: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"第2个训练集的损失为: {:.2f}%\".format(loss * 100))\n",
    "xval_adv2 = perturbation_gen(X_val2.copy(),Y_val2.copy(),eps)\n",
    "loss, accuracy = model.evaluate(x=xval_adv2, y=Y_val2)\n",
    "print(\"第2个验证集的准确率为: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"第2个验证集的损失为: {:.2f}%\".format(loss * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2bb80b3-da4d-4051-8fca-3c3ecb10b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bim\n",
    "eps_iter = (eps/0.025)*0.001\n",
    "xtrain_adv3 =  basic_iterative_method(model, X_train3.copy(), eps=eps, eps_iter=eps_iter ,nb_iter=num_iter, norm=np.inf, \n",
    "                                      # clip_min=-1,clip_max=1,\n",
    "                                      rand_init=None,rand_minmax=0.3)\n",
    "loss, accuracy = model.evaluate(x=xtrain_adv3, y=Y_train3)\n",
    "print(\"第3个训练集的准确率为: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"第3个训练集的损失为: {:.2f}%\".format(loss * 100))\n",
    "xval_adv3 = basic_iterative_method(model, X_val3.copy(), eps=eps, eps_iter=eps_iter ,nb_iter=num_iter, norm=np.inf, \n",
    "                                      # clip_min=-1,clip_max=1,\n",
    "                                   rand_init=None,rand_minmax=0.3)\n",
    "loss, accuracy = model.evaluate(x=xval_adv3, y=Y_val3)\n",
    "print(\"第3个验证集的准确率为: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"第3个验证集的损失为: {:.2f}%\".format(loss * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7008e40a-3f80-4bea-b4fe-e0dc27cec4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i=5\n",
    "xtrain_adv4 = carlini_wagner_l2.carlini_wagner_l2(model,X_train4.copy(),binary_search_steps=5,max_iterations=max_i,\n",
    "                                                confidence=0.0,initial_const=0.5,learning_rate=0.03,)\n",
    "loss, accuracy = model.evaluate(x=xtrain_adv4, y=Y_train4)\n",
    "print(\"第4个训练集的准确率为: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"第4个训练集的损失为: {:.2f}%\".format(loss * 100))\n",
    "xval_adv4 = carlini_wagner_l2.carlini_wagner_l2(model,X_val4.copy(),binary_search_steps=5,max_iterations=max_i,\n",
    "                                                confidence=0.0,initial_const=0.5,learning_rate=0.03,)\n",
    "loss, accuracy = model.evaluate(x=xval_adv4, y=Y_val4)\n",
    "print(\"第4个验证集的准确率为: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"第4个验证集的损失为: {:.2f}%\".format(loss * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae80d3e-bc5e-425b-bfaa-e957027fdeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainl = np.concatenate((xtrain_adv1,xtrain_adv2,xtrain_adv3,xtrain_adv4,X_train1,X_train2,X_train3,X_train4),axis=0)\n",
    "xvall = np.concatenate((xval_adv1,xval_adv2,xval_adv3,xval_adv4,X_val1,X_val2,X_val3,X_val4),axis=0)\n",
    "print(xtrainl.shape,xvall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecec8f71-a479-4511-99c1-a2f4ab3d8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrainl = np.zeros((len(xtrainl)))\n",
    "inter = int(len(ytrainl)/2)\n",
    "ytrainl[:inter]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f67dc46-f27a-4f8c-bcb2-1a6cedc55618",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvall = np.zeros((len(xvall)))\n",
    "inter1 = int(len(yvall)/2)\n",
    "yvall[:inter1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6116c85d-8194-4747-950e-6c60ab95ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrainl.shape)\n",
    "print(xvall.shape)\n",
    "print(ytrainl.shape)\n",
    "print(yvall.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9c8d1-8303-4ba2-a9f5-127a3e3e5674",
   "metadata": {},
   "source": [
    "## 定义攻击检测模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ce26baf-2edd-4f67-a17a-af96c396717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_model(n_outputs=1):\n",
    "    inputs = Input(shape=(128, 2)) \n",
    "    conv1 = Conv1D(filters=128, kernel_size=8, activation='relu', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    lstm1 = LSTM(128, return_sequences=True)(conv1)\n",
    "    attention = Attention()([lstm1, lstm1])\n",
    "    sumlayer = SumLayer()(attention)\n",
    "    BN1 = BatchNormalization()(sumlayer)\n",
    "    dense1 = Dense(256, activation='relu')(BN1)\n",
    "    output = Dense(n_outputs, activation='sigmoid')(dense1)  # 输出一个概率值\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4708ecd8-bea7-4784-bbe6-1ad979bb2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 2)]          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 121, 128)          2176      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 121, 128)          131584    \n",
      "                                                                 \n",
      " sum_layer_2 (SumLayer)      (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,553\n",
      "Trainable params: 167,297\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "detect_model = detect_model(1)\n",
    "detect_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8cfc299-b334-4114-96a4-61fe8a44c7e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath = 'detect_model'\n",
    "detect_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = detect_model.fit(xtrainl, ytrainl, epochs=200, verbose=1,batch_size=64,validation_data=(xvall,yvall),\n",
    "                     callbacks=[\n",
    "                         keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "                         keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, verbose=1, patience=10,min_lr=0.000001),\n",
    "                         keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=1, mode='auto')\n",
    "                     ]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "721ad223-5500-4ee2-975f-2ef1a12d76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_model =  tf.keras.models.load_model('detect_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b2722-a261-4539-acee-85233f608bf3",
   "metadata": {},
   "source": [
    "## 测试模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abe24d17-6db3-4652-a38b-1198e974bc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(6600, 128, 2)\n",
      "(2200, 128, 2)\n",
      "(1320, 128, 2)\n",
      "(6600, 11)\n",
      "(2200, 11)\n",
      "(1320, 11)\n"
     ]
    }
   ],
   "source": [
    "reload(rml128_dtiny)\n",
    "(mods,snrs,lbl),(X_train11,Y_train11),(X_val11,Y_val11),(X_test11,Y_test11),(train_idx11,val_idx11,test_idx11) = \\\n",
    "    rml128_dtiny.load_data()\n",
    "classes = mods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f25f16c-a86e-498f-8965-fa207432038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.025\n",
    "\n",
    "xtest_adv11 = projected_gradient_descent(model, X_test11.copy(), eps, eps_iterr,num_iter, np.inf,\n",
    "                                       clip_min=-1,clip_max=1,rand_init=rand_init, rand_minmax=0.3)\n",
    "# xtest_adv11 = perturbation_gen(X_test11.copy(),Y_test11.copy(), eps)\n",
    "\n",
    "# eps_iter = (eps/0.025)*0.001\n",
    "# xtest_adv11 = basic_iterative_method(model, X_test11.copy(), eps, eps_iter=eps_iter ,nb_iter=num_iter, norm=np.inf, \n",
    "#                                       rand_init=None,rand_minmax=0.3)\n",
    "\n",
    "# xtest_adv11 = carlini_wagner_l2.carlini_wagner_l2(model,X_test11.copy(),binary_search_steps=5,max_iterations=10,\n",
    "#                                                 confidence=0.0,initial_const=0.5,learning_rate=0.03,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc2fd31-0752-4870-818a-27613c328c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest11 = np.ones((len(xtest_adv11)))\n",
    "loss, accuracy = detect_model.evaluate(x=xtest_adv11, y=ytest11)\n",
    "print(\"准确率为: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5537188f-bfea-465d-bc47-e2c0b23aeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest11 = np.zeros((len(X_test11)))\n",
    "loss, accuracy = detect_model.evaluate(x=X_test11, y=ytest11)\n",
    "print(\"准确率为: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfa201-e049-44ad-9b8e-0694aaa84600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd28af-f44b-47b8-bf84-841bd1897ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f3b0bb-75a6-420b-8faf-b5abd1671cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f69e1-f1ea-402c-b91d-b773b3d723c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee36c4-fc77-4b07-8af1-a1e9c5877336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa74f48-3e26-46a3-ba7f-0d35098fd98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de6e61-1b37-4b7d-89ce-495fd902f1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a2468-62e0-4813-8737-cf3c1f3664d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201b9ba-bd8e-458e-a991-732d50831966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wtfgpu",
   "language": "python",
   "name": "wtfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
